{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification using Random Forest and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"forest.jpg\" width=\"500\" height=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to predict handwritten numerical digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.41.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dr_sam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "# Let us install the tensorflow module\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C:\\\\Users\\\\Dr_Sam\\\\Desktop\\\\CHM SESSION JULY-NOV 2023\\\\WISDOM CLASS\\\\DATA SCIENCE-MACHINE LEARNING\\\\(WISDOM) Lecture 4- Feature Engineering and Classification Algorithms\\\\Lecture 4- Feature Eng'g and Classification Algorithms\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadd all the datasets\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2     3     4     5    6    7    8    9   ...   54   55   56  \\\n",
       "0  0.0  0.0  5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  5.0  0.0  0.0   \n",
       "3  0.0  0.0  7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  9.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "    57   58    59    60    61   62   63  \n",
       "0  0.0  6.0  13.0  10.0   0.0  0.0  0.0  \n",
       "1  0.0  0.0  11.0  16.0  10.0  0.0  0.0  \n",
       "2  0.0  0.0   3.0  11.0  16.0  9.0  0.0  \n",
       "3  0.0  7.0  13.0  13.0   9.0  0.0  0.0  \n",
       "4  0.0  0.0   2.0  16.0   4.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the digits.data to Dataframe\n",
    "dg_df = pd.DataFrame(digits.data)\n",
    "dg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the target column\n",
    "dg_df['target'] = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1     2     3     4     5     6    7    8    9  ...   55   56   57  \\\n",
       "0   0.0  0.0   5.0  13.0   9.0   1.0   0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1   0.0  0.0   0.0  12.0  13.0   5.0   0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2   0.0  0.0   0.0   4.0  15.0  12.0   0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3   0.0  0.0   7.0  15.0  13.0   1.0   0.0  0.0  0.0  8.0  ...  0.0  0.0  0.0   \n",
       "4   0.0  0.0   0.0   1.0  11.0   0.0   0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5   0.0  0.0  12.0  10.0   0.0   0.0   0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "6   0.0  0.0   0.0  12.0  13.0   0.0   0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "7   0.0  0.0   7.0   8.0  13.0  16.0  15.0  1.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "8   0.0  0.0   9.0  14.0   8.0   1.0   0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "9   0.0  0.0  11.0  12.0   0.0   0.0   0.0  0.0  0.0  2.0  ...  0.0  0.0  0.0   \n",
       "10  0.0  0.0   1.0   9.0  15.0  11.0   0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "11  0.0  0.0   0.0   0.0  14.0  13.0   1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "      58    59    60    61   62   63  target  \n",
       "0    6.0  13.0  10.0   0.0  0.0  0.0       0  \n",
       "1    0.0  11.0  16.0  10.0  0.0  0.0       1  \n",
       "2    0.0   3.0  11.0  16.0  9.0  0.0       2  \n",
       "3    7.0  13.0  13.0   9.0  0.0  0.0       3  \n",
       "4    0.0   2.0  16.0   4.0  0.0  0.0       4  \n",
       "5    9.0  16.0  16.0  10.0  0.0  0.0       5  \n",
       "6    1.0   9.0  15.0  11.0  3.0  0.0       6  \n",
       "7   13.0   5.0   0.0   0.0  0.0  0.0       7  \n",
       "8   11.0  16.0  15.0  11.0  1.0  0.0       8  \n",
       "9    9.0  12.0  13.0   3.0  0.0  0.0       9  \n",
       "10   1.0  10.0  13.0   3.0  0.0  0.0       0  \n",
       "11   0.0   1.0  13.0  16.0  1.0  0.0       1  \n",
       "\n",
       "[12 rows x 65 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the first 12 rows\n",
    "dg_df[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "60        0\n",
       "61        0\n",
       "62        0\n",
       "63        0\n",
       "target    0\n",
       "Length: 65, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values\n",
    "dg_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 65)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of the dataframe\n",
    "dg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for number of unique values in the target\n",
    "dg_df.target.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio = 0.56 %\n"
     ]
    }
   ],
   "source": [
    "# Calculating ratio of target to records\n",
    "ratio = dg_df['target'].nunique()/dg_df.shape[0]\n",
    "print(f'ratio = {np.round(ratio*100,2)} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22fb295c750>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the various handwriting digit\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting our datasets into training and test\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits.data,digits.target,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1437"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg_model = LogisticRegression()\n",
    "lg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=20)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=20)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=20)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score: 96.94%\n",
      "RandomForest Score: 96.67%\n"
     ]
    }
   ],
   "source": [
    "print(f'Logistic Regression Score: {np.round(lg_model.score(X_test,y_test)*100,2)}%') \n",
    "print(f'RandomForest Score: {np.round(rf_model.score(X_test,y_test)*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22fb4caecd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Picking up a random sample\n",
    "plt.matshow(digits.images[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_model.predict([digits.data[45]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.predict([digits.data[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 34,  0,  0,  0,  0,  0,  0,  1,  0],\n",
       "       [ 0,  1, 27,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 34,  0,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0, 37,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1, 34,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 37,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 32,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0,  0,  0, 34,  0],\n",
       "       [ 0,  0,  0,  1,  0,  0,  0,  0,  3, 36]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Playing around with confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_predicted = lg_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predicted)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(120.72222222222221, 0.5, 'Actual values')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using seaborn and plt for better visualization\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Actual values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the TensorFlow Digit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadd all the datasets\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2     3     4     5    6    7    8    9   ...   54   55   56  \\\n",
       "0  0.0  0.0  5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  5.0  0.0  0.0   \n",
       "3  0.0  0.0  7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  9.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "    57   58    59    60    61   62   63  \n",
       "0  0.0  6.0  13.0  10.0   0.0  0.0  0.0  \n",
       "1  0.0  0.0  11.0  16.0  10.0  0.0  0.0  \n",
       "2  0.0  0.0   3.0  11.0  16.0  9.0  0.0  \n",
       "3  0.0  7.0  13.0  13.0   9.0  0.0  0.0  \n",
       "4  0.0  0.0   2.0  16.0   4.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the digits.data to Dataframe\n",
    "dg_df = pd.DataFrame(digits.data)\n",
    "dg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1     2     3     4     5    6    7    8    9  ...   55   56  \\\n",
       "0     0.0  0.0   5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1     0.0  0.0   0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2     0.0  0.0   0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "3     0.0  0.0   7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  0.0  0.0   \n",
       "4     0.0  0.0   0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "...   ...  ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1792  0.0  0.0   4.0  10.0  13.0   6.0  0.0  0.0  0.0  1.0  ...  0.0  0.0   \n",
       "1793  0.0  0.0   6.0  16.0  13.0  11.0  1.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1794  0.0  0.0   1.0  11.0  15.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1795  0.0  0.0   2.0  10.0   7.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1796  0.0  0.0  10.0  14.0   8.0   1.0  0.0  0.0  0.0  2.0  ...  0.0  0.0   \n",
       "\n",
       "       57   58    59    60    61   62   63  target  \n",
       "0     0.0  6.0  13.0  10.0   0.0  0.0  0.0       0  \n",
       "1     0.0  0.0  11.0  16.0  10.0  0.0  0.0       1  \n",
       "2     0.0  0.0   3.0  11.0  16.0  9.0  0.0       2  \n",
       "3     0.0  7.0  13.0  13.0   9.0  0.0  0.0       3  \n",
       "4     0.0  0.0   2.0  16.0   4.0  0.0  0.0       4  \n",
       "...   ...  ...   ...   ...   ...  ...  ...     ...  \n",
       "1792  0.0  2.0  14.0  15.0   9.0  0.0  0.0       9  \n",
       "1793  0.0  6.0  16.0  14.0   6.0  0.0  0.0       0  \n",
       "1794  0.0  2.0   9.0  13.0   6.0  0.0  0.0       8  \n",
       "1795  0.0  5.0  12.0  16.0  12.0  0.0  0.0       9  \n",
       "1796  1.0  8.0  12.0  14.0  12.0  1.0  0.0       8  \n",
       "\n",
       "[1797 rows x 65 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the target column\n",
    "dg_df['target'] = digits.target\n",
    "dg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features and target variables\n",
    "x_features = dg_df.iloc[:,0:64]\n",
    "y_target = dg_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1     2     3     4     5    6    7    8    9   ...   54   55  \\\n",
       "0     0.0  0.0   5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1     0.0  0.0   0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2     0.0  0.0   0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  5.0  0.0   \n",
       "3     0.0  0.0   7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  9.0  0.0   \n",
       "4     0.0  0.0   0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "...   ...  ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1792  0.0  0.0   4.0  10.0  13.0   6.0  0.0  0.0  0.0  1.0  ...  4.0  0.0   \n",
       "1793  0.0  0.0   6.0  16.0  13.0  11.0  1.0  0.0  0.0  0.0  ...  1.0  0.0   \n",
       "1794  0.0  0.0   1.0  11.0  15.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1795  0.0  0.0   2.0  10.0   7.0   0.0  0.0  0.0  0.0  0.0  ...  2.0  0.0   \n",
       "1796  0.0  0.0  10.0  14.0   8.0   1.0  0.0  0.0  0.0  2.0  ...  8.0  0.0   \n",
       "\n",
       "       56   57   58    59    60    61   62   63  \n",
       "0     0.0  0.0  6.0  13.0  10.0   0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  11.0  16.0  10.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0   3.0  11.0  16.0  9.0  0.0  \n",
       "3     0.0  0.0  7.0  13.0  13.0   9.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0   2.0  16.0   4.0  0.0  0.0  \n",
       "...   ...  ...  ...   ...   ...   ...  ...  ...  \n",
       "1792  0.0  0.0  2.0  14.0  15.0   9.0  0.0  0.0  \n",
       "1793  0.0  0.0  6.0  16.0  14.0   6.0  0.0  0.0  \n",
       "1794  0.0  0.0  2.0   9.0  13.0   6.0  0.0  0.0  \n",
       "1795  0.0  0.0  5.0  12.0  16.0  12.0  0.0  0.0  \n",
       "1796  0.0  1.0  8.0  12.0  14.0  12.0  1.0  0.0  \n",
       "\n",
       "[1797 rows x 64 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, RidgeClassifier,SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid, RadiusNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier,ExtraTreesClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a train_test split of the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_features,y_target,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87       4.0\n",
       "911      0.0\n",
       "1223     1.0\n",
       "522      4.0\n",
       "1211     1.0\n",
       "        ... \n",
       "1634     0.0\n",
       "1610     0.0\n",
       "314      0.0\n",
       "1323     2.0\n",
       "625     16.0\n",
       "Name: 5, Length: 1437, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking X_train data\n",
    "X_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22fbfc27bd0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Picking up a random sample\n",
    "plt.matshow(digits.images[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the actual data\n",
    "y_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, RidgeClassifier,SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid, RadiusNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier,ExtraTreesClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score,mean_absolute_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 = GradientBoostingClassifier(random_state=1)\n",
    "reg2 = RandomForestClassifier(random_state=1)\n",
    "classifiers = [\n",
    "    GaussianNB(),\n",
    "    MultinomialNB(),\n",
    "    ComplementNB(),\n",
    "    BernoulliNB(),\n",
    "    LogisticRegression(),\n",
    "    Lasso(),\n",
    "    RidgeClassifier(),\n",
    "    SGDClassifier(),\n",
    "    SVC(),\n",
    "    LinearSVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    MLPClassifier(hidden_layer_sizes=(5,), random_state=1, max_iter=500, warm_start=True),\n",
    "    BaggingClassifier(estimator=ExtraTreesClassifier(),n_estimators=64, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=64, max_depth=10, min_samples_split=2, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=5),\n",
    "    ExtraTreesClassifier(n_estimators=64, max_depth=6, min_samples_split=2, random_state=0),\n",
    "    GradientBoostingClassifier(n_estimators=64, max_depth=10, min_samples_split=2, random_state=0),\n",
    "    HistGradientBoostingClassifier(),\n",
    "    NearestCentroid(),\n",
    "    VotingClassifier([(\"gb\", reg1), (\"rf\", reg2)])\n",
    "    #StackingClassifier(estimators=20)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a performance dataframe\n",
    "performance_df = pd.DataFrame(columns= ['train_time','pred_time','train_score','test_score',\"ml_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "Training score: 88.17,  Test Score: 62.870000000000005\n",
      "\n",
      "MultinomialNB()\n",
      "Training score: 90.47,  Test Score: 70.92\n",
      "\n",
      "ComplementNB()\n",
      "Training score: 82.05,  Test Score: 47.46\n",
      "\n",
      "BernoulliNB()\n",
      "Training score: 86.92,  Test Score: 58.879999999999995\n",
      "\n",
      "LogisticRegression()\n",
      "Training score: 100.0,  Test Score: 94.85\n",
      "\n",
      "Lasso()\n",
      "Training score: 46.43,  Test Score: 46.62\n",
      "\n",
      "RidgeClassifier()\n",
      "Training score: 94.5,  Test Score: 86.33\n",
      "\n",
      "SGDClassifier()\n",
      "Training score: 97.63,  Test Score: 92.17\n",
      "\n",
      "SVC()\n",
      "Training score: 99.72,  Test Score: 98.19\n",
      "\n",
      "LinearSVC()\n",
      "Training score: 99.51,  Test Score: 93.04\n",
      "\n",
      "KNeighborsClassifier()\n",
      "Training score: 98.96,  Test Score: 96.7\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(5,), max_iter=500, random_state=1,\n",
      "              warm_start=True)\n",
      "Training score: 97.49,  Test Score: 81.8\n",
      "\n",
      "BaggingClassifier(estimator=ExtraTreesClassifier(), n_estimators=64,\n",
      "                  random_state=0)\n",
      "Training score: 100.0,  Test Score: 97.28\n",
      "\n",
      "RandomForestClassifier(max_depth=10, n_estimators=64, random_state=0)\n",
      "Training score: 100.0,  Test Score: 94.63000000000001\n",
      "\n",
      "AdaBoostClassifier(n_estimators=5)\n",
      "Training score: 26.86,  Test Score: -3.05\n",
      "\n",
      "ExtraTreesClassifier(max_depth=6, n_estimators=64, random_state=0)\n",
      "Training score: 97.98,  Test Score: 91.99000000000001\n",
      "\n",
      "GradientBoostingClassifier(max_depth=10, n_estimators=64, random_state=0)\n",
      "Training score: 100.0,  Test Score: 78.24\n",
      "\n",
      "HistGradientBoostingClassifier()\n",
      "Training score: 100.0,  Test Score: 95.61\n",
      "\n",
      "NearestCentroid()\n",
      "Training score: 90.33,  Test Score: 76.5\n",
      "\n",
      "VotingClassifier(estimators=[('gb', GradientBoostingClassifier(random_state=1)),\n",
      "                             ('rf', RandomForestClassifier(random_state=1))])\n",
      "Training score: 100.0,  Test Score: 94.89\n",
      "\n",
      "Simulation Completed\n"
     ]
    }
   ],
   "source": [
    "head = len(classifiers)\n",
    "for model in classifiers[:head]:\n",
    "    start = time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_score = np.round(model.score(X_train, y_train)*100,2)\n",
    "    train_time = time() - start\n",
    "    \n",
    "    start = time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_score = np.round(r2_score(y_test, y_pred),4)*100\n",
    "    predict_time = time()-start\n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    performance_df.loc[classifiers.index(model)] = [train_time,predict_time,train_score,test_score,str(model)]\n",
    "    print(f'Training score: {train_score},  Test Score: {test_score}')\n",
    "    print()\n",
    "print('Simulation Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_time</th>\n",
       "      <th>pred_time</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>ml_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>48.430209</td>\n",
       "      <td>14.790651</td>\n",
       "      <td>100.00</td>\n",
       "      <td>97.28</td>\n",
       "      <td>BaggingClassifier(estimator=ExtraTreesClassifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>37.375896</td>\n",
       "      <td>0.098001</td>\n",
       "      <td>100.00</td>\n",
       "      <td>95.61</td>\n",
       "      <td>HistGradientBoostingClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18.316549</td>\n",
       "      <td>0.312528</td>\n",
       "      <td>100.00</td>\n",
       "      <td>94.89</td>\n",
       "      <td>VotingClassifier(estimators=[('gb', GradientBo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.201038</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>100.00</td>\n",
       "      <td>94.85</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.853522</td>\n",
       "      <td>0.199999</td>\n",
       "      <td>100.00</td>\n",
       "      <td>94.63</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31.396651</td>\n",
       "      <td>0.042999</td>\n",
       "      <td>100.00</td>\n",
       "      <td>78.24</td>\n",
       "      <td>GradientBoostingClassifier(max_depth=10, n_est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.334487</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>99.72</td>\n",
       "      <td>98.19</td>\n",
       "      <td>SVC()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.154999</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>99.51</td>\n",
       "      <td>93.04</td>\n",
       "      <td>LinearSVC()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.465084</td>\n",
       "      <td>0.041999</td>\n",
       "      <td>98.96</td>\n",
       "      <td>96.70</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.360001</td>\n",
       "      <td>0.203038</td>\n",
       "      <td>97.98</td>\n",
       "      <td>91.99</td>\n",
       "      <td>ExtraTreesClassifier(max_depth=6, n_estimators...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>97.63</td>\n",
       "      <td>92.17</td>\n",
       "      <td>SGDClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.284667</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>97.49</td>\n",
       "      <td>81.80</td>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(5,), max_ite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.013999</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>94.50</td>\n",
       "      <td>86.33</td>\n",
       "      <td>RidgeClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009999</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>90.47</td>\n",
       "      <td>70.92</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.039001</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>90.33</td>\n",
       "      <td>76.50</td>\n",
       "      <td>NearestCentroid()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.022003</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>88.17</td>\n",
       "      <td>62.87</td>\n",
       "      <td>GaussianNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>86.92</td>\n",
       "      <td>58.88</td>\n",
       "      <td>BernoulliNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>82.05</td>\n",
       "      <td>47.46</td>\n",
       "      <td>ComplementNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>46.43</td>\n",
       "      <td>46.62</td>\n",
       "      <td>Lasso()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.147997</td>\n",
       "      <td>0.065002</td>\n",
       "      <td>26.86</td>\n",
       "      <td>-3.05</td>\n",
       "      <td>AdaBoostClassifier(n_estimators=5)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_time  pred_time  train_score  test_score  \\\n",
       "12   48.430209  14.790651       100.00       97.28   \n",
       "17   37.375896   0.098001       100.00       95.61   \n",
       "19   18.316549   0.312528       100.00       94.89   \n",
       "4     0.201038   0.002999       100.00       94.85   \n",
       "13    0.853522   0.199999       100.00       94.63   \n",
       "16   31.396651   0.042999       100.00       78.24   \n",
       "8     0.334487   0.057514        99.72       98.19   \n",
       "9     0.154999   0.002000        99.51       93.04   \n",
       "10    0.465084   0.041999        98.96       96.70   \n",
       "15    0.360001   0.203038        97.98       91.99   \n",
       "7     0.091000   0.002998        97.63       92.17   \n",
       "11    3.284667   0.012000        97.49       81.80   \n",
       "6     0.013999   0.001998        94.50       86.33   \n",
       "1     0.009999   0.004001        90.47       70.92   \n",
       "18    0.039001   0.012000        90.33       76.50   \n",
       "0     0.022003   0.005998        88.17       62.87   \n",
       "3     0.012000   0.002998        86.92       58.88   \n",
       "2     0.008000   0.003000        82.05       47.46   \n",
       "5     0.009001   0.002000        46.43       46.62   \n",
       "14    0.147997   0.065002        26.86       -3.05   \n",
       "\n",
       "                                             ml_model  \n",
       "12  BaggingClassifier(estimator=ExtraTreesClassifi...  \n",
       "17                   HistGradientBoostingClassifier()  \n",
       "19  VotingClassifier(estimators=[('gb', GradientBo...  \n",
       "4                                LogisticRegression()  \n",
       "13  RandomForestClassifier(max_depth=10, n_estimat...  \n",
       "16  GradientBoostingClassifier(max_depth=10, n_est...  \n",
       "8                                               SVC()  \n",
       "9                                         LinearSVC()  \n",
       "10                             KNeighborsClassifier()  \n",
       "15  ExtraTreesClassifier(max_depth=6, n_estimators...  \n",
       "7                                     SGDClassifier()  \n",
       "11  MLPClassifier(hidden_layer_sizes=(5,), max_ite...  \n",
       "6                                   RidgeClassifier()  \n",
       "1                                     MultinomialNB()  \n",
       "18                                  NearestCentroid()  \n",
       "0                                        GaussianNB()  \n",
       "3                                       BernoulliNB()  \n",
       "2                                      ComplementNB()  \n",
       "5                                             Lasso()  \n",
       "14                 AdaBoostClassifier(n_estimators=5)  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df.sort_values(by=['train_score','test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Scaling to improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.0\n",
       "1      8.0\n",
       "2     16.0\n",
       "3     16.0\n",
       "4     16.0\n",
       "      ... \n",
       "59    16.0\n",
       "60    16.0\n",
       "61    16.0\n",
       "62    16.0\n",
       "63    16.0\n",
       "Length: 64, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_features.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling each data by the maximum value (16)\n",
    "scale_Xtrain = X_train/16\n",
    "scale_Xtest = X_test/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5      6    7    8       9   \\\n",
       "934   0.0  0.0625  0.6250  0.9375  0.9375  0.1875  0.000  0.0  0.0  0.3750   \n",
       "652   0.0  0.0000  0.0000  0.8125  0.1875  0.0000  0.000  0.0  0.0  0.0000   \n",
       "1647  0.0  0.0000  0.0625  0.8125  1.0000  0.1250  0.000  0.0  0.0  0.0000   \n",
       "944   0.0  0.0000  0.4375  0.8125  0.6250  0.0625  0.000  0.0  0.0  0.0625   \n",
       "1742  0.0  0.2500  0.9375  0.9375  0.5000  0.0000  0.000  0.0  0.0  0.5000   \n",
       "...   ...     ...     ...     ...     ...     ...    ...  ...  ...     ...   \n",
       "1174  0.0  0.0000  0.3125  0.8125  1.0000  1.0000  0.375  0.0  0.0  0.0000   \n",
       "453   0.0  0.0000  0.1250  0.7500  1.0000  0.3750  0.000  0.0  0.0  0.0000   \n",
       "417   0.0  0.0000  0.3125  0.8750  0.6875  0.0625  0.000  0.0  0.0  0.0000   \n",
       "1539  0.0  0.0000  0.0000  0.4375  1.0000  0.1250  0.000  0.0  0.0  0.0000   \n",
       "1429  0.0  0.0000  0.0000  0.6250  0.7500  0.0000  0.000  0.0  0.0  0.0000   \n",
       "\n",
       "      ...      54     55   56      57      58      59      60      61      62  \\\n",
       "934   ...  0.8125  0.000  0.0  0.0000  0.6250  1.0000  1.0000  1.0000  0.6875   \n",
       "652   ...  1.0000  0.125  0.0  0.0000  0.0000  0.6875  1.0000  0.8750  0.4375   \n",
       "1647  ...  0.0625  0.000  0.0  0.0000  0.0625  0.6875  1.0000  0.5000  0.0000   \n",
       "944   ...  0.6875  0.000  0.0  0.0000  0.4375  0.8125  1.0000  0.9375  0.2500   \n",
       "1742  ...  0.1875  0.000  0.0  0.4375  0.8750  0.6875  0.0000  0.0000  0.0000   \n",
       "...   ...     ...    ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "1174  ...  0.0000  0.000  0.0  0.0000  0.3750  0.6875  0.0000  0.0000  0.0000   \n",
       "453   ...  0.9375  0.000  0.0  0.0000  0.0625  0.5000  0.7500  0.7500  0.3750   \n",
       "417   ...  0.6875  0.000  0.0  0.0000  0.3750  1.0000  0.8750  0.7500  0.1875   \n",
       "1539  ...  0.0000  0.000  0.0  0.0000  0.0000  0.5625  0.9375  0.0625  0.0000   \n",
       "1429  ...  0.0000  0.000  0.0  0.0000  0.0000  0.8125  0.6875  0.0000  0.0000   \n",
       "\n",
       "       63  \n",
       "934   0.0  \n",
       "652   0.0  \n",
       "1647  0.0  \n",
       "944   0.0  \n",
       "1742  0.0  \n",
       "...   ...  \n",
       "1174  0.0  \n",
       "453   0.0  \n",
       "417   0.0  \n",
       "1539  0.0  \n",
       "1429  0.0  \n",
       "\n",
       "[360 rows x 64 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 = GradientBoostingClassifier(random_state=1)\n",
    "reg2 = RandomForestClassifier(random_state=1)\n",
    "classifiers = [\n",
    "    GaussianNB(),\n",
    "    MultinomialNB(),\n",
    "    ComplementNB(),\n",
    "    BernoulliNB(),\n",
    "    LogisticRegression(),\n",
    "    Lasso(),\n",
    "    RidgeClassifier(),\n",
    "    SGDClassifier(),\n",
    "    SVC(),\n",
    "    LinearSVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    MLPClassifier(hidden_layer_sizes=(5,), random_state=1, max_iter=500, warm_start=True),\n",
    "    BaggingClassifier(estimator=ExtraTreesClassifier(),n_estimators=64, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=64, max_depth=10, min_samples_split=2, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=5),\n",
    "    ExtraTreesClassifier(n_estimators=64, max_depth=6, min_samples_split=2, random_state=0),\n",
    "    GradientBoostingClassifier(n_estimators=64, max_depth=10, min_samples_split=2, random_state=0),\n",
    "    HistGradientBoostingClassifier(),\n",
    "    NearestCentroid(),\n",
    "    VotingClassifier([(\"gb\", reg1), (\"rf\", reg2)])\n",
    "    #StackingClassifier(estimators=20)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a performance dataframe\n",
    "scale_performance_df = pd.DataFrame(columns= ['train_time','pred_time','train_score','test_score','ml_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "Training score: 88.17,  Test Score: 62.870000000000005\n",
      "\n",
      "MultinomialNB()\n",
      "Training score: 90.47,  Test Score: 70.92\n",
      "\n",
      "ComplementNB()\n",
      "Training score: 82.12,  Test Score: 47.599999999999994\n",
      "\n",
      "BernoulliNB()\n",
      "Training score: 86.92,  Test Score: 58.879999999999995\n",
      "\n",
      "LogisticRegression()\n",
      "Training score: 98.26,  Test Score: 96.95\n",
      "\n",
      "Lasso()\n",
      "Training score: 0.0,  Test Score: -0.0\n",
      "\n",
      "RidgeClassifier()\n",
      "Training score: 94.43,  Test Score: 84.95\n",
      "\n",
      "SGDClassifier()\n",
      "Training score: 97.77,  Test Score: 95.0\n",
      "\n",
      "SVC()\n",
      "Training score: 99.72,  Test Score: 98.19\n",
      "\n",
      "LinearSVC()\n",
      "Training score: 98.89,  Test Score: 96.08\n",
      "\n",
      "KNeighborsClassifier()\n",
      "Training score: 98.96,  Test Score: 96.7\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(5,), max_iter=500, random_state=1,\n",
      "              warm_start=True)\n",
      "Training score: 95.62,  Test Score: 75.22999999999999\n",
      "\n",
      "BaggingClassifier(estimator=ExtraTreesClassifier(), n_estimators=64,\n",
      "                  random_state=0)\n",
      "Training score: 100.0,  Test Score: 97.28\n",
      "\n",
      "RandomForestClassifier(max_depth=10, n_estimators=64, random_state=0)\n",
      "Training score: 100.0,  Test Score: 94.63000000000001\n",
      "\n",
      "AdaBoostClassifier(n_estimators=5)\n",
      "Training score: 26.86,  Test Score: -3.05\n",
      "\n",
      "ExtraTreesClassifier(max_depth=6, n_estimators=64, random_state=0)\n",
      "Training score: 97.98,  Test Score: 91.99000000000001\n",
      "\n",
      "GradientBoostingClassifier(max_depth=10, n_estimators=64, random_state=0)\n",
      "Training score: 100.0,  Test Score: 78.24\n",
      "\n",
      "HistGradientBoostingClassifier()\n",
      "Training score: 100.0,  Test Score: 95.61\n",
      "\n",
      "NearestCentroid()\n",
      "Training score: 90.33,  Test Score: 76.5\n",
      "\n",
      "VotingClassifier(estimators=[('gb', GradientBoostingClassifier(random_state=1)),\n",
      "                             ('rf', RandomForestClassifier(random_state=1))])\n",
      "Training score: 100.0,  Test Score: 94.89\n",
      "\n",
      "Simulation Completed\n"
     ]
    }
   ],
   "source": [
    "head = len(classifiers)\n",
    "for model in classifiers[:head]:\n",
    "    start = time()\n",
    "    model.fit(scale_Xtrain, y_train)\n",
    "    train_score = np.round(model.score(scale_Xtrain, y_train)*100,2)\n",
    "    train_time = time() - start\n",
    "    \n",
    "    start = time()\n",
    "    y_pred = model.predict(scale_Xtest)\n",
    "    test_score = np.round(r2_score(y_test, y_pred),4)*100\n",
    "    predict_time = time()-start\n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    scale_performance_df.loc[classifiers.index(model)] = [train_time,predict_time,train_score,test_score,str(model)]\n",
    "    print(f'Training score: {train_score},  Test Score: {test_score}')\n",
    "    print()\n",
    "print('Simulation Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_time</th>\n",
       "      <th>pred_time</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>ml_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>46.097415</td>\n",
       "      <td>16.765870</td>\n",
       "      <td>100.00</td>\n",
       "      <td>97.28</td>\n",
       "      <td>BaggingClassifier(estimator=ExtraTreesClassifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36.536760</td>\n",
       "      <td>0.116996</td>\n",
       "      <td>100.00</td>\n",
       "      <td>95.61</td>\n",
       "      <td>HistGradientBoostingClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17.822539</td>\n",
       "      <td>0.294984</td>\n",
       "      <td>100.00</td>\n",
       "      <td>94.89</td>\n",
       "      <td>VotingClassifier(estimators=[('gb', GradientBo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.819041</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>94.63</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28.101272</td>\n",
       "      <td>0.040998</td>\n",
       "      <td>100.00</td>\n",
       "      <td>78.24</td>\n",
       "      <td>GradientBoostingClassifier(max_depth=10, n_est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.333542</td>\n",
       "      <td>0.063998</td>\n",
       "      <td>99.72</td>\n",
       "      <td>98.19</td>\n",
       "      <td>SVC()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.181522</td>\n",
       "      <td>0.046999</td>\n",
       "      <td>98.96</td>\n",
       "      <td>96.70</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.104005</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>98.89</td>\n",
       "      <td>96.08</td>\n",
       "      <td>LinearSVC()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260998</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>98.26</td>\n",
       "      <td>96.95</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.426056</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>97.98</td>\n",
       "      <td>91.99</td>\n",
       "      <td>ExtraTreesClassifier(max_depth=6, n_estimators...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.076999</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>97.77</td>\n",
       "      <td>95.00</td>\n",
       "      <td>SGDClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.091977</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>95.62</td>\n",
       "      <td>75.23</td>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(5,), max_ite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>94.43</td>\n",
       "      <td>84.95</td>\n",
       "      <td>RidgeClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009997</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>90.47</td>\n",
       "      <td>70.92</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.041002</td>\n",
       "      <td>0.014998</td>\n",
       "      <td>90.33</td>\n",
       "      <td>76.50</td>\n",
       "      <td>NearestCentroid()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>88.17</td>\n",
       "      <td>62.87</td>\n",
       "      <td>GaussianNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020001</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>86.92</td>\n",
       "      <td>58.88</td>\n",
       "      <td>BernoulliNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006998</td>\n",
       "      <td>0.005003</td>\n",
       "      <td>82.12</td>\n",
       "      <td>47.60</td>\n",
       "      <td>ComplementNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.158992</td>\n",
       "      <td>0.052997</td>\n",
       "      <td>26.86</td>\n",
       "      <td>-3.05</td>\n",
       "      <td>AdaBoostClassifier(n_estimators=5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>Lasso()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_time  pred_time  train_score  test_score  \\\n",
       "12   46.097415  16.765870       100.00       97.28   \n",
       "17   36.536760   0.116996       100.00       95.61   \n",
       "19   17.822539   0.294984       100.00       94.89   \n",
       "13    0.819041   0.310000       100.00       94.63   \n",
       "16   28.101272   0.040998       100.00       78.24   \n",
       "8     0.333542   0.063998        99.72       98.19   \n",
       "10    0.181522   0.046999        98.96       96.70   \n",
       "9     0.104005   0.003000        98.89       96.08   \n",
       "4     0.260998   0.004000        98.26       96.95   \n",
       "15    0.426056   0.316000        97.98       91.99   \n",
       "7     0.076999   0.001998        97.77       95.00   \n",
       "11    3.091977   0.003000        95.62       75.23   \n",
       "6     0.014000   0.004001        94.43       84.95   \n",
       "1     0.009997   0.001998        90.47       70.92   \n",
       "18    0.041002   0.014998        90.33       76.50   \n",
       "0     0.027000   0.006000        88.17       62.87   \n",
       "3     0.020001   0.003998        86.92       58.88   \n",
       "2     0.006998   0.005003        82.12       47.60   \n",
       "14    0.158992   0.052997        26.86       -3.05   \n",
       "5     0.006999   0.002999         0.00       -0.00   \n",
       "\n",
       "                                             ml_model  \n",
       "12  BaggingClassifier(estimator=ExtraTreesClassifi...  \n",
       "17                   HistGradientBoostingClassifier()  \n",
       "19  VotingClassifier(estimators=[('gb', GradientBo...  \n",
       "13  RandomForestClassifier(max_depth=10, n_estimat...  \n",
       "16  GradientBoostingClassifier(max_depth=10, n_est...  \n",
       "8                                               SVC()  \n",
       "10                             KNeighborsClassifier()  \n",
       "9                                         LinearSVC()  \n",
       "4                                LogisticRegression()  \n",
       "15  ExtraTreesClassifier(max_depth=6, n_estimators...  \n",
       "7                                     SGDClassifier()  \n",
       "11  MLPClassifier(hidden_layer_sizes=(5,), max_ite...  \n",
       "6                                   RidgeClassifier()  \n",
       "1                                     MultinomialNB()  \n",
       "18                                  NearestCentroid()  \n",
       "0                                        GaussianNB()  \n",
       "3                                       BernoulliNB()  \n",
       "2                                      ComplementNB()  \n",
       "14                 AdaBoostClassifier(n_estimators=5)  \n",
       "5                                             Lasso()  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_performance_df.sort_values(by=['train_score','test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use sklearn.datasets iris flower dataset to train your model using logistic regression. You need to figure out accuracy \n",
    "of your model and use that to predict different samples in your test dataset. In iris dataset there are 150 samples containing following features,\n",
    "\n",
    "1. Sepal Length\n",
    "2. Sepal Width \n",
    "3. Petal Length \n",
    "4. Petal Width\n",
    "\n",
    "Using above 4 features you will clasify a flower in one of the three categories,\n",
    "\n",
    "1. Setosa\n",
    "2. Versicolour\n",
    "3. Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img height=300 width=300 src=\"iris_petal_sepal.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
